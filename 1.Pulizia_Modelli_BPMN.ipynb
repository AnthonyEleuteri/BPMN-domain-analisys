{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a6878b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'encoding del file './BPMN 2.csv' è: utf-8\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18247 entries, 0 to 22575\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   CollectionName  18247 non-null  object\n",
      " 1   Labels          18247 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 427.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CollectionName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00001177, s00001177, s00001430, s00001430, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000262, s00000266, s00000267, s00000268, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000309, s00000310, s00000311, s00000312, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000336, s00000337, s00000338, s00000339]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000256, s00000307, s00000335, s00000358, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000843, s00000843, s00001196, s00001196, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000520, s00000527]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00001294, s00001294, s00001355, s00001355, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000409, s00000598, s00000599, s00000600, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000527, s00000621, s00000623, s00000624, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000642, s00000643, s00000645]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000026]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000527, s00000671]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000743, s00000743, s00000743, s00000744, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[BIT]</td>\n",
       "      <td>[s00000348, s00000348:2, s00000596, s00000596:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CollectionName                                             Labels\n",
       "0           [BIT]  [s00001177, s00001177, s00001430, s00001430, s...\n",
       "1           [BIT]  [s00000262, s00000266, s00000267, s00000268, s...\n",
       "2           [BIT]  [s00000309, s00000310, s00000311, s00000312, s...\n",
       "3           [BIT]       [s00000336, s00000337, s00000338, s00000339]\n",
       "4           [BIT]  [s00000256, s00000307, s00000335, s00000358, s...\n",
       "5           [BIT]  [s00000843, s00000843, s00001196, s00001196, s...\n",
       "6           [BIT]                             [s00000520, s00000527]\n",
       "7           [BIT]  [s00001294, s00001294, s00001355, s00001355, s...\n",
       "8           [BIT]  [s00000409, s00000598, s00000599, s00000600, s...\n",
       "9           [BIT]  [s00000527, s00000621, s00000623, s00000624, s...\n",
       "10          [BIT]                  [s00000642, s00000643, s00000645]\n",
       "11          [BIT]                                        [s00000026]\n",
       "12          [BIT]                             [s00000527, s00000671]\n",
       "14          [BIT]  [s00000743, s00000743, s00000743, s00000744, s...\n",
       "15          [BIT]  [s00000348, s00000348:2, s00000596, s00000596:..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import chardet\n",
    "\n",
    "%run \"./support_functions.ipynb\"\n",
    "\n",
    "file_path = \"./BPMN 2.csv\"\n",
    "output_file_path = \"./BPMNcleaned.csv\"\n",
    "\n",
    "# vedo l'encoding del file\n",
    "input_file_encoding = get_file_encoding(file_path)\n",
    "print(f\"L'encoding del file '{file_path}' è: {input_file_encoding}\")\n",
    "\n",
    "# Save the data of the .csv file in a Variable\n",
    "df = pd.read_csv(file_path, sep=';', engine='python', encoding=input_file_encoding)\n",
    "\n",
    "# Drop the specified columns\n",
    "df = df.iloc[:, [0,-2]]\n",
    "\n",
    "# Save cleaned data in a new .csv file\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Remove duplicates in the DataFrame\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Clean the column from \"^^^\"\n",
    "df = df.fillna('')\n",
    "df = df.applymap(lambda x: x.split(\"^^^\") if isinstance(x, str) else x)\n",
    "\n",
    "# Save the file .csv\n",
    "df.to_csv(output_file_path, index=False, sep=';')\n",
    "\n",
    "df.info()\n",
    "df.head(15)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3283c3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'encoding del file './BPMNcleaned.csv' è: utf-8\n",
      "Sono state eliminate 5796\n",
      "Righe eliminate: /n       CollectionName                                             Labels  \\\n",
      "777        ['BPMAI']  [ArztuntersuchtnachVollst?хndigkeit, Gewebewir...   \n",
      "781        ['BPMAI']  [ANO, ANO, DefaultInputSet, DefaultInputSet, D...   \n",
      "782        ['BPMAI']  [Datenbereitsvorhanden?, Ja, Ja, Ja, Kontendat...   \n",
      "783        ['BPMAI']       [A, B, B, DefaultInputSet, DefaultOutputSet]   \n",
      "788        ['BPMAI']                             [Writefinancialreport]   \n",
      "...              ...                                                ...   \n",
      "18241        ['eCH']  [52PatentpflichtAnlassabkl?хren, AusnahmenzurA...   \n",
      "18243        ['eCH']  [Antragauf?ҐnderungVernehmlassungsweglangstatt...   \n",
      "18244        ['eCH']  [Abteilungsleiter, allesi.O., allesi.O., Anpas...   \n",
      "18245        ['eCH']  [Abschlagszahlungm??glich, Abschlagszahlungm??...   \n",
      "18246        ['eCH']  [BesprechungmitBeteiligten, Bewilligungerteile...   \n",
      "\n",
      "       is_desired_language  \n",
      "777                  False  \n",
      "781                  False  \n",
      "782                  False  \n",
      "783                  False  \n",
      "788                  False  \n",
      "...                    ...  \n",
      "18241                False  \n",
      "18243                False  \n",
      "18244                False  \n",
      "18245                False  \n",
      "18246                False  \n",
      "\n",
      "[5796 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import chardet\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from langdetect import detect\n",
    "\n",
    "%run \"./support_functions.ipynb\"\n",
    "\n",
    "input_file_path = './BPMNcleaned.csv'\n",
    "output_file_path = './BPMNcleanedlanguages.csv'\n",
    "\n",
    "\n",
    "# vedo l'encoding del file\n",
    "input_file_encoding = get_file_encoding(input_file_path)\n",
    "print(f\"L'encoding del file '{input_file_path}' è: {input_file_encoding}.\")\n",
    "\n",
    "# leggo il file CSV in un DataFrame\n",
    "df = pd.read_csv(input_file_path, sep=';', engine='python', encoding=input_file_encoding)\n",
    "\n",
    "# imposto la lingua che vogliamo mantenere e ritorno se la stringa appartiene \n",
    "def is_desired_language(text):\n",
    "    target_language='en'\n",
    "    try:\n",
    "        detected_language = detect(text)\n",
    "        return detected_language == target_language\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "# metodo che cicla ogni etichetta\n",
    "def is_desired_language_list(labels):\n",
    "    return any(is_desired_language(str(label)) for label in labels)\n",
    "\n",
    "# filtro ogni riga del dataframe e successivamente pulisco le righe non consone\n",
    "def filter_dataframe(df):\n",
    "    df['Labels'] = df['Labels'].apply(lambda labels: literal_eval(labels))\n",
    "    df['is_desired_language'] = df['Labels'].apply(is_desired_language_list)\n",
    "        \n",
    "    discarded_rows = df[~df['is_desired_language']]\n",
    "    filtered_df = df[df['is_desired_language']].drop(['is_desired_language'], axis=1)\n",
    "\n",
    "    \n",
    "    # stampo le righe eliminate\n",
    "    print(f\"Sono state eliminate {len(discarded_rows)} righe.\")\n",
    "    print(f\"Righe eliminate: /n {discarded_rows}\")\n",
    "    #print(discarded_rows)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# applico il filtro al DataFrame\n",
    "filtered_df = filter_dataframe(df)\n",
    "\n",
    "# salvo il DataFrame risultante in un nuovo file CSV\n",
    "filtered_df.to_csv(output_file_path, index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d74d6ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'encoding del file './BPMNcleanedlanguages.csv' è: utf-8\n",
      "Numero di diversi domini nel testing_data:\n",
      "CollectionName\n",
      "['BPMAI']      3015\n",
      "['Camunda']     481\n",
      "['BIT']         233\n",
      "['eCH']           6\n",
      "Name: count, dtype: int64\n",
      "    CollectionName                                             Labels\n",
      "552        ['BIT']  ['s00001950', 's00001950', 's00004213', 's0000...\n",
      "331        ['BIT']  ['s00002058', 's00002058', 's00002058', 's0000...\n",
      "161        ['BIT']  ['s00001789', 's00001789', 's00001789', 's0000...\n",
      "60         ['BIT']  ['s00001130', 's00001130', 's00001130', 's0000...\n",
      "477        ['BIT']  ['s00001397', 's00001397', 's00001397', 's0000...\n",
      "\n",
      "Numero di diversi domini nel training_data:\n",
      "CollectionName\n",
      "['BPMAI']      7035\n",
      "['Camunda']    1123\n",
      "['BIT']         544\n",
      "['eCH']          14\n",
      "Name: count, dtype: int64\n",
      "    CollectionName                                             Labels\n",
      "520        ['BIT']  ['s00003750', 's00003750', 's00003750', 's0000...\n",
      "400        ['BIT']                         ['s00002566', 's00003073']\n",
      "242        ['BIT']  ['s00000068', 's00000098', 's00000130', 's0000...\n",
      "178        ['BIT']  ['s00000018', 's00000070', 's00000074', 's0000...\n",
      "416        ['BIT']  ['s00003168', 's00003168', 's00003168', 's0000...\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import chardet\n",
    "import pandas as pd\n",
    "\n",
    "%run \"./support_functions.ipynb\"\n",
    "\n",
    "input_file_path = './BPMNcleanedlanguages.csv'\n",
    "output_training_file = './BPMNtraining.csv'\n",
    "output_testing_file = './BPMNtesting.csv'\n",
    "\n",
    "# vedo l'encoding del file\n",
    "input_file_encoding = get_file_encoding(input_file_path)\n",
    "print(f\"L'encoding del file '{input_file_path}' è: {input_file_encoding}\")\n",
    "\n",
    "# Loading the DataFrame\n",
    "df = pd.read_csv(input_file_path, sep=';', engine='python', encoding=input_file_encoding)\n",
    "\n",
    "# Funzione che divide il DataFrame in proporzion\n",
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "# Funzione che da un dataframe ritorna un dataframe di dataframe divisi\n",
    "def split_by_collectionname(data):\n",
    "    divided_data = {}\n",
    "    for collectionname in data['CollectionName'].unique():\n",
    "        divided_data[collectionname] = data[data['CollectionName'] == collectionname].copy()\n",
    "    return divided_data\n",
    "\n",
    "# Funzione che per ogni chiave (collectionname) divide in train e testing\n",
    "def creating_train_test_dataframe(data, test_ratio):\n",
    "    training_df = []\n",
    "    testing_df = []\n",
    "    # Dividi il DataFrame per CollectionName\n",
    "    divided_data = split_by_collectionname(data)\n",
    "    # Per ogni CollectionName, dividi il DataFrame in train e test\n",
    "    for collectionname, data in divided_data.items():\n",
    "        train_df, test_df = split_train_test(data, test_ratio)\n",
    "        training_df.append(train_df)\n",
    "        testing_df.append(test_df)\n",
    "        \n",
    "        training_data=pd.concat(training_df)\n",
    "        testing_data=pd.concat(testing_df) \n",
    "    \n",
    "    return training_data, testing_data  \n",
    "        \n",
    "# Prende randomicamente e in percentuale le righe del df per training e testing\n",
    "# training_data, testing_data = split_train_test(df, 0.3)\n",
    "training_data, testing_data = creating_train_test_dataframe(df, 0.3)\n",
    "\n",
    "\n",
    "# Stampo le prime 20 righe di training e testing\n",
    "# Stampa il numero dei diversi domini nel DataFrame di testing\n",
    "print(\"Numero di diversi domini nel testing_data:\")\n",
    "print(testing_data['CollectionName'].value_counts())\n",
    "print(testing_data.head())\n",
    "\n",
    "# Stampa il numero dei diversi domini nel DataFrame di training\n",
    "print(\"\\nNumero di diversi domini nel training_data:\")\n",
    "print(training_data['CollectionName'].value_counts())\n",
    "print(training_data.head())\n",
    "\n",
    "# salva in file rispettivi per training e testing\n",
    "training_data.to_csv(output_training_file, index=False, sep=';')\n",
    "testing_data.to_csv(output_testing_file, index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b6bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
